{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa963ec-fb6f-4758-88dc-82b7bc11161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nadee\\anaconda3\\envs\\session2\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import QFileDialog, QMessageBox, QComboBox\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from PIL import Image\n",
    "\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "from PyQt5.QtWidgets import QMessageBox\n",
    "from deepface import DeepFace\n",
    "import traceback\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import QMessageBox\n",
    "import io\n",
    "from PIL import Image\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# MySQL configuration\n",
    "mysql_config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"\",\n",
    "    \"database\": \"images_db\"\n",
    "}\n",
    "\n",
    "# Function to read and convert an image into byte array\n",
    "def read_image(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        img_byte_array = io.BytesIO()\n",
    "        img.save(img_byte_array, format=img.format)\n",
    "        return img_byte_array.getvalue()\n",
    "\n",
    "# Insert image into the database\n",
    "def insert_image_to_db(cursor, image_name, image_data):\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO images_store (image_name, image_column) VALUES (%s, %s)\",\n",
    "        (image_name, image_data),\n",
    "    )\n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.setMinimumSize(QtCore.QSize(1200, 633))\n",
    "        MainWindow.setMaximumSize(QtCore.QSize(1200, 633))\n",
    "        MainWindow.setBaseSize(QtCore.QSize(1200, 633))\n",
    "\n",
    "        # Central widget setup\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "\n",
    "        # Add tab widget\n",
    "        self.tabWidget = QtWidgets.QTabWidget(self.centralwidget)\n",
    "        self.tabWidget.setGeometry(QtCore.QRect(0, 0, 1200, 600))\n",
    "\n",
    "        # First Tab: Face Recognition from Database\n",
    "        self.tab1 = QtWidgets.QWidget()\n",
    "        self.tab1.setObjectName(\"tab1\")\n",
    "\n",
    "        self.image_viewer = QtWidgets.QLabel(self.tab1)\n",
    "        self.image_viewer.setGeometry(QtCore.QRect(100, 50, 1000, 351))\n",
    "        self.image_viewer.setScaledContents(True)\n",
    "        self.image_viewer.setObjectName(\"image_viewer\")\n",
    "\n",
    "        self.load_button = QtWidgets.QPushButton(self.tab1)\n",
    "        self.load_button.setGeometry(QtCore.QRect(300, 450, 221, 41))\n",
    "        self.load_button.setObjectName(\"load_button\")\n",
    "\n",
    "        self.match_button = QtWidgets.QPushButton(self.tab1)\n",
    "        self.match_button.setGeometry(QtCore.QRect(600, 450, 221, 41))\n",
    "        self.match_button.setObjectName(\"match_button\")\n",
    "\n",
    "        # ComboBox for model selection\n",
    "        self.model_combobox = QComboBox(self.tab1)\n",
    "        self.model_combobox.setGeometry(QtCore.QRect(450, 500, 221, 41))\n",
    "        self.model_combobox.setObjectName(\"model_combobox\")\n",
    "        self.model_combobox.addItems([\"VGG-Face\", \"OpenFace\", \"Facenet\", \"DeepFace\"])\n",
    "\n",
    "        self.tabWidget.addTab(self.tab1, \"Face Recognition\")\n",
    "\n",
    "        # Second Tab: Real-Time Face Recognition (Webcam)\n",
    "        self.tab2 = QtWidgets.QWidget()\n",
    "        self.tab2.setObjectName(\"tab2\")\n",
    "\n",
    "        # Webcam-related widgets in second tab\n",
    "        self.webcam_image_viewer = QtWidgets.QLabel(self.tab2)\n",
    "        self.webcam_image_viewer.setGeometry(QtCore.QRect(100, 50, 1000, 351))\n",
    "        self.webcam_image_viewer.setScaledContents(True)\n",
    "        self.webcam_image_viewer.setObjectName(\"webcam_image_viewer\")\n",
    "\n",
    "        self.open_webcam_button = QtWidgets.QPushButton(self.tab2)\n",
    "        self.open_webcam_button.setGeometry(QtCore.QRect(50, 450, 221, 41))\n",
    "        self.open_webcam_button.setObjectName(\"open_webcam_button\")\n",
    "\n",
    "        self.stop_webcam_button = QtWidgets.QPushButton(self.tab2)\n",
    "        self.stop_webcam_button.setGeometry(QtCore.QRect(450, 450, 221, 41))\n",
    "        self.stop_webcam_button.setObjectName(\"stop_webcam_button\")\n",
    "\n",
    "        self.model_combobox_2 = QComboBox(self.tab2)\n",
    "        self.model_combobox_2.setGeometry(QtCore.QRect(450, 500, 221, 41))\n",
    "        self.model_combobox_2.setObjectName(\"model_combobox_2\")\n",
    "        self.model_combobox_2.addItems([\"VGG-Face\", \"OpenFace\", \"Facenet\", \"DeepFace\"])\n",
    "        # Add this button to your UI in the second tab\n",
    "        self.capture_button = QtWidgets.QPushButton(self.tab2)\n",
    "        self.capture_button.setGeometry(QtCore.QRect(900, 450, 221, 41))\n",
    "        self.capture_button.setObjectName(\"capture_button\")\n",
    "        self.capture_button.setText(\"Capture\")\n",
    "\n",
    "        self.tabWidget.addTab(self.tab2, \"Real-Time Face Recognition\")\n",
    "        # Third Tab: Manage Dataset\n",
    "        self.tab3 = QtWidgets.QWidget()\n",
    "        self.tab3.setObjectName(\"tab3\")\n",
    "        self.name_edit_box = QtWidgets.QLineEdit(self.tab3)\n",
    "        self.name_edit_box.setGeometry(QtCore.QRect(20, 60, 200, 30))\n",
    "        self.name_edit_box.setObjectName(\"name_edit_box\")\n",
    "        self.add_face_button = QtWidgets.QPushButton(self.tab3)\n",
    "        self.add_face_button.setGeometry(QtCore.QRect(20, 120, 200, 40))\n",
    "        self.add_face_button.setObjectName(\"add_face_button\")\n",
    "        self.clear_button = QtWidgets.QPushButton(self.tab3)\n",
    "        self.clear_button.setGeometry(QtCore.QRect(20, 180, 200, 40))\n",
    "        self.clear_button.setObjectName(\"clear_button\")\n",
    "        self.remove_face_button = QtWidgets.QPushButton(self.tab3)\n",
    "        self.remove_face_button.setGeometry(QtCore.QRect(20, 240, 200, 40))\n",
    "        self.remove_face_button.setObjectName(\"remove_face_button\")\n",
    "        self.face_list_button = QtWidgets.QPushButton(self.tab3)\n",
    "        self.face_list_button.setGeometry(QtCore.QRect(20, 300, 200, 40))\n",
    "        self.face_list_button.setObjectName(\"face_list_button\")\n",
    "        self.img_label = QtWidgets.QLabel(self.tab3)\n",
    "        self.img_label.setGeometry(QtCore.QRect(300, 50, 400, 360))\n",
    "        self.img_label.setScaledContents(True)\n",
    "        self.img_label.setObjectName(\"img_label\")\n",
    "        self.list_label = QtWidgets.QLabel(self.tab3)\n",
    "        self.list_label.setGeometry(QtCore.QRect(750, 50, 400, 360))\n",
    "        self.list_label.setScaledContents(False)\n",
    "        self.list_label.setWordWrap(True)\n",
    "        self.list_label.setObjectName(\"list_label\")\n",
    "        self.tabWidget.addTab(self.tab3, \"Manage Dataset\")\n",
    "        # Create the \"Clear Label\" button on the third tab\n",
    "        self.clear_label_button = QtWidgets.QPushButton(self.tab3)\n",
    "        self.clear_label_button.setGeometry(QtCore.QRect(20, 360, 200, 40))  # Adjust position as needed\n",
    "        self.clear_label_button.setObjectName(\"clear_label_button\")\n",
    "        self.clear_label_button.setText(\"Clear Label\")\n",
    "\n",
    "        # Connect the button to the method that clears the label\n",
    "        self.clear_label_button.clicked.connect(self.clear_label)\n",
    "\n",
    "        # Connect buttons to functions\n",
    "        self.load_button.clicked.connect(self.load_image_for_recognition)\n",
    "        self.match_button.clicked.connect(self.match_face)\n",
    "        self.open_webcam_button.clicked.connect(self.start_webcam)\n",
    "        self.stop_webcam_button.clicked.connect(self.stop_webcam)\n",
    "        # Button connections\n",
    "        self.add_face_button.clicked.connect(self.add_face_to_dataset)\n",
    "        self.clear_button.clicked.connect(self.clear_face_entry)\n",
    "        self.remove_face_button.clicked.connect(self.remove_face_from_dataset)\n",
    "        self.face_list_button.clicked.connect(self.list_faces_in_dataset)\n",
    "        self.capture_button.clicked.connect(self.capture_frame_and_stop_webcam)\n",
    "\n",
    "        # Central widget setup\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "\n",
    "        # Menubar and statusbar setup\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 801, 26))\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        # Call retranslateUi to set up text for all UI components\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        \n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"Face Recognition and Management\"))\n",
    "        self.capture_button.setText(_translate(\"MainWindow\", \"Capture\"))\n",
    "        self.load_button.setText(_translate(\"MainWindow\", \"Load Image\"))\n",
    "        self.match_button.setText(_translate(\"MainWindow\", \"Match\"))\n",
    "        self.open_webcam_button.setText(_translate(\"MainWindow\", \"Open Webcam\"))\n",
    "        self.stop_webcam_button.setText(_translate(\"MainWindow\", \"Stop Webcam\"))\n",
    "        self.add_face_button.setText(_translate(\"MainWindow\", \"Add Face\"))\n",
    "        self.clear_button.setText(_translate(\"MainWindow\", \"Clear\"))\n",
    "        self.remove_face_button.setText(_translate(\"MainWindow\", \"Remove Face\"))\n",
    "        self.face_list_button.setText(_translate(\"MainWindow\", \"Face List\"))\n",
    "\n",
    "    def load_image_for_recognition(self):\n",
    "        options = QFileDialog.Options()\n",
    "        file_path, _ = QFileDialog.getOpenFileName(None, \"Choose Image\", \"\", \"Image Files (*.jpg *.jpeg *.png)\", options=options)\n",
    "        if file_path:\n",
    "            self.recognition_image_path = file_path\n",
    "            pixmap = QtGui.QPixmap(file_path)\n",
    "            self.image_viewer.setPixmap(pixmap)\n",
    "    def clear_label(self):\n",
    "        # Clears the text of the QLabel used for the list\n",
    "        self.list_label.setText(\"\")  # This clears the text in the label\n",
    "\n",
    "    def match_face(self):\n",
    "        if not hasattr(self, 'recognition_image_path'):\n",
    "            QMessageBox.warning(None, \"Error\", \"Please load an image to match.\")\n",
    "            return\n",
    "\n",
    "        # Get selected model from ComboBox\n",
    "        selected_model = self.model_combobox.currentText()\n",
    "\n",
    "        # Perform recognition using DeepFace\n",
    "        self.recognize_face_with_deepface(self.recognition_image_path, selected_model)\n",
    "\n",
    "    def start_webcam(self):\n",
    "        # Initialize the webcam (OpenCV)\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "    \n",
    "        # Check if the webcam opened successfully\n",
    "        if not self.cap.isOpened():\n",
    "            QMessageBox.warning(None, \"Error\", \"Could not open webcam.\")\n",
    "            return\n",
    "    \n",
    "        self.webcam_running = True\n",
    "        self.capture_frame()\n",
    "\n",
    "    def stop_webcam(self):\n",
    "        if hasattr(self, 'cap') and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "        self.webcam_running = False\n",
    "        self.webcam_image_viewer.clear()\n",
    "\n",
    "    def capture_frame(self):\n",
    "        if self.webcam_running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                # Perform face detection and draw bounding boxes\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    \n",
    "                for (top, right, bottom, left) in face_locations:\n",
    "                    # Draw bounding box around detected face\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    \n",
    "                # Convert the frame to QPixmap for displaying in QLabel\n",
    "                height, width, channel = frame.shape\n",
    "                bytes_per_line = 3 * width\n",
    "                q_img = QtGui.QImage(frame.data, width, height, bytes_per_line, QtGui.QImage.Format_BGR888)\n",
    "                self.webcam_image_viewer.setPixmap(QtGui.QPixmap.fromImage(q_img))\n",
    "    \n",
    "            # Call capture_frame again to get the next frame\n",
    "            QtCore.QTimer.singleShot(1, self.capture_frame)\n",
    "\n",
    "    def capture_face(self):\n",
    "        self.identify_faces = True\n",
    "\n",
    "    def load_encodings_from_database(self):\n",
    "        known_face_encodings = []\n",
    "        known_face_names = []\n",
    "        try:\n",
    "            db_connection = mysql.connector.connect(\n",
    "                host=\"localhost\",\n",
    "                user=\"root\",\n",
    "                password=\"\",  \n",
    "                database=\"images_db\" \n",
    "            )\n",
    "            cursor = db_connection.cursor()\n",
    "            cursor.execute(\"SELECT image_name, image_column FROM images_store\")  \n",
    "            results = cursor.fetchall()\n",
    "\n",
    "            for name, image_blob in results:\n",
    "                image = face_recognition.load_image_file(BytesIO(image_blob))  \n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "                if face_encodings:  \n",
    "                    known_face_encodings.append(face_encodings[0])  \n",
    "                    known_face_names.append(name) \n",
    "\n",
    "            cursor.close()\n",
    "            db_connection.close()\n",
    "\n",
    "            return known_face_encodings, known_face_names\n",
    "\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error: {err}\")\n",
    "            return [], [] \n",
    "    def recognize_face_with_deepface(self, image_path, model_name):\n",
    "        try:\n",
    "            # Load known encodings and names from the database\n",
    "            known_face_encodings, known_face_names = self.load_encodings_from_database()\n",
    "    \n",
    "            if not known_face_encodings:\n",
    "                QMessageBox.warning(None, \"No Known Faces\", \"No faces found in the database for recognition.\")\n",
    "                return\n",
    "    \n",
    "            # Load the image for recognition\n",
    "            image = cv2.imread(image_path)\n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "            face_locations = face_recognition.face_locations(rgb_image)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "    \n",
    "            if not face_encodings:\n",
    "                QMessageBox.warning(None, \"No Faces Detected\", \"No faces were detected in the uploaded image.\")\n",
    "                return\n",
    "    \n",
    "            # Process each detected face\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "    \n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "    \n",
    "                # Draw a bounding box around the face\n",
    "                cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)  # Red color with thickness of 2\n",
    "    \n",
    "                # Put the name below the bounding box\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(image, name, (left, bottom + 20), font, 1.0, (255, 255, 255), 1)\n",
    "    \n",
    "            # Convert the image back to Qt format for displaying\n",
    "            height, width, channel = image.shape\n",
    "            bytes_per_line = 3 * width\n",
    "            q_img = QtGui.QImage(image.data, width, height, bytes_per_line, QtGui.QImage.Format_BGR888)\n",
    "    \n",
    "            # Show the image with bounding box and name\n",
    "            self.image_viewer.setPixmap(QtGui.QPixmap.fromImage(q_img))\n",
    "    \n",
    "        except Exception as e:\n",
    "            error_message = f\"An error occurred while processing the image:\\n\\n{str(e)}\"\n",
    "            QMessageBox.warning(None, \"Error\", error_message)\n",
    "    # Functions for managing dataset\n",
    "    def add_face_to_dataset(self):\n",
    "        name = self.name_edit_box.text()\n",
    "        if not name:\n",
    "            QMessageBox.warning(None, \"Error\", \"Enter a name.\")\n",
    "            return\n",
    "        file_path, _ = QFileDialog.getOpenFileName(None, \"Choose Image\", \"\", \"Images (*.jpg *.jpeg *.png)\")\n",
    "        if file_path:\n",
    "            try:\n",
    "                image_data = read_image(file_path)\n",
    "                db_connection = mysql.connector.connect(**mysql_config)\n",
    "                cursor = db_connection.cursor()\n",
    "                insert_image_to_db(cursor, name, image_data)\n",
    "                db_connection.commit()\n",
    "                cursor.close()\n",
    "                db_connection.close()\n",
    "                self.img_label.setPixmap(QtGui.QPixmap(file_path))\n",
    "                QMessageBox.information(None, \"Success\", \"Face added successfully.\")\n",
    "            except Error as e:\n",
    "                QMessageBox.critical(None, \"Error\", str(e))\n",
    "\n",
    "    def clear_face_entry(self):\n",
    "        self.name_edit_box.clear()\n",
    "        self.img_label.clear()\n",
    "\n",
    "    def remove_face_from_dataset(self):\n",
    "        name = self.name_edit_box.text()\n",
    "        if not name:\n",
    "            QMessageBox.warning(None, \"Error\", \"Enter a name.\")\n",
    "            return\n",
    "        try:\n",
    "            db_connection = mysql.connector.connect(**mysql_config)\n",
    "            cursor = db_connection.cursor()\n",
    "            cursor.execute(\"DELETE FROM images_store WHERE image_name = %s\", (name,))\n",
    "            db_connection.commit()\n",
    "            cursor.close()\n",
    "            db_connection.close()\n",
    "            QMessageBox.information(None, \"Success\", \"Face removed successfully.\")\n",
    "        except Error as e:\n",
    "            QMessageBox.critical(None, \"Error\", str(e))\n",
    "\n",
    "    \n",
    "    def capture_frame_and_stop_webcam(self):\n",
    "        if hasattr(self, 'cap') and self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                # Stop webcam feed\n",
    "                self.cap.release()\n",
    "                self.webcam_running = False\n",
    "    \n",
    "                # Perform face recognition on the captured frame\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                face_locations = face_recognition.face_locations(rgb_frame)\n",
    "                face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    \n",
    "                # Load known encodings from the database\n",
    "                known_face_encodings, known_face_names = self.load_encodings_from_database()\n",
    "    \n",
    "                # Process each detected face\n",
    "                for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                    name = \"Unknown\"\n",
    "                    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "    \n",
    "                    if matches[best_match_index]:\n",
    "                        name = known_face_names[best_match_index]\n",
    "    \n",
    "                    # Draw a bounding box around the face\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    \n",
    "                    # Put the name below the bounding box\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(frame, name, (left, bottom + 20), font, 1.0, (255, 255, 255), 1)\n",
    "    \n",
    "                # Convert the captured frame back to QPixmap for display\n",
    "                height, width, channel = frame.shape\n",
    "                bytes_per_line = 3 * width\n",
    "                q_img = QtGui.QImage(frame.data, width, height, bytes_per_line, QtGui.QImage.Format_BGR888)\n",
    "                self.webcam_image_viewer.setPixmap(QtGui.QPixmap.fromImage(q_img))\n",
    "    \n",
    "\n",
    "    def list_faces_in_dataset(self):\n",
    "        try:\n",
    "            db_connection = mysql.connector.connect(**mysql_config)\n",
    "            cursor = db_connection.cursor()\n",
    "            cursor.execute(\"SELECT image_name FROM images_store\")\n",
    "            names = [row[0] for row in cursor.fetchall()]\n",
    "            cursor.close()\n",
    "            db_connection.close()\n",
    "            self.list_label.setText(\"\\n\".join(names) if names else \"No faces found.\")\n",
    "        except Error as e:\n",
    "            QMessageBox.critical(None, \"Error\", str(e))\n",
    "# Main execution\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    \n",
    "    MainWindow.closeEvent = lambda event: app.quit()  \n",
    "    \n",
    "    MainWindow.show()\n",
    "    app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cd426-b4a7-4410-b2cb-2f1c4a8e5a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
