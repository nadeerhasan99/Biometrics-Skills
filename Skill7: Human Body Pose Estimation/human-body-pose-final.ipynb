{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-05T13:52:49.872824Z",
     "iopub.status.busy": "2025-01-05T13:52:49.872509Z",
     "iopub.status.idle": "2025-01-05T13:52:50.173328Z",
     "shell.execute_reply": "2025-01-05T13:52:50.172475Z",
     "shell.execute_reply.started": "2025-01-05T13:52:49.872793Z"
    },
    "id": "2h_LLRpbKX9f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T13:52:50.174535Z",
     "iopub.status.busy": "2025-01-05T13:52:50.174209Z",
     "iopub.status.idle": "2025-01-05T13:52:51.282570Z",
     "shell.execute_reply": "2025-01-05T13:52:51.281670Z",
     "shell.execute_reply.started": "2025-01-05T13:52:50.174513Z"
    },
    "id": "8ax5vg_9KX9g",
    "outputId": "ebbc1ac7-01e0-4313-891f-154ee0ca37ff",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/mpii-human-pose\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "mpii_human_pose_path = kagglehub.dataset_download('harshpatel66/mpii-human-pose')\n",
    "print(\"Path to dataset files:\", mpii_human_pose_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T13:52:55.061282Z",
     "iopub.status.busy": "2025-01-05T13:52:55.060998Z",
     "iopub.status.idle": "2025-01-05T13:53:36.899899Z",
     "shell.execute_reply": "2025-01-05T13:53:36.899092Z",
     "shell.execute_reply.started": "2025-01-05T13:52:55.061259Z"
    },
    "id": "RZwQ93DFKX9g",
    "outputId": "b76429c7-3760-44a9-eed6-139f3d2e75f9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: protobuf, sounddevice, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.5 which is incompatible.\n",
      "google-cloud-bigtable 2.26.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed mediapipe-0.10.20 protobuf-4.25.5 sounddevice-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T13:53:41.093419Z",
     "iopub.status.busy": "2025-01-05T13:53:41.093126Z",
     "iopub.status.idle": "2025-01-05T13:53:44.206868Z",
     "shell.execute_reply": "2025-01-05T13:53:44.205767Z",
     "shell.execute_reply.started": "2025-01-05T13:53:41.093397Z"
    },
    "id": "-YaOt1OMKX9h",
    "outputId": "a1b00a17-c518-4c07-fd76-9413efd5fc8a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T15:24:57.897129Z",
     "iopub.status.busy": "2025-01-05T15:24:57.896802Z",
     "iopub.status.idle": "2025-01-05T15:30:33.947980Z",
     "shell.execute_reply": "2025-01-05T15:30:33.947217Z",
     "shell.execute_reply.started": "2025-01-05T15:24:57.897099Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Mean Average Precision (mAP)...\n",
      "\n",
      "Threshold: 0.2\n",
      "Average PCK @ 0.2: 16.86%\n",
      "\n",
      "Threshold: 0.3\n",
      "Average PCK @ 0.3: 29.94%\n",
      "\n",
      "Threshold: 0.6\n",
      "Average PCK @ 0.6: 61.36%\n",
      "Mean Average Precision (mAP): 36.0545\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# For static images (example paths for your setup)\n",
    "image_dir = '/kaggle/input/mpii-human-pose/mpii_human_pose_v1/images'\n",
    "json_annotations_path = '/kaggle/input/mpii-human-pose/mpii_annotations.json'\n",
    "csv_keypoints_path = '/kaggle/input/mpii-human-pose/mpii_human_pose.csv'\n",
    "\n",
    "# Load CSV and JSON data\n",
    "ground_truth_df = pd.read_csv(csv_keypoints_path)\n",
    "with open(json_annotations_path, 'r') as f:\n",
    "    mpii_annotations = json.load(f)\n",
    "\n",
    "# Prepare Pose model\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Define the mapping from MediaPipe's 33 keypoints to MPII's 14 keypoints\n",
    "# Only use the first 14 keypoints from MediaPipe\n",
    "keypoint_mapping = {\n",
    "    0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13\n",
    "    # 33 predicted -> 14 ground truth mapping\n",
    "}\n",
    "\n",
    "# Calculate PCK (Percentage of Correct Keypoints)\n",
    "def calculate_pck(predicted_keypoints, ground_truth_keypoints, image_width, image_height, threshold=0.05):\n",
    "    threshold_distance = threshold * np.sqrt(image_width**2 + image_height**2)\n",
    "    \n",
    "    correct_keypoints = 0\n",
    "    total_keypoints = 0\n",
    "\n",
    "    for idx in range(len(predicted_keypoints)):\n",
    "        pred_x, pred_y = predicted_keypoints[idx]\n",
    "        if idx >= len(ground_truth_keypoints):\n",
    "            continue  # Skip if there are more predicted keypoints than ground truth\n",
    "        \n",
    "        gt_x, gt_y = ground_truth_keypoints[idx]\n",
    "        \n",
    "        if gt_x == -1 or gt_y == -1:  # Ignore missing ground truth points\n",
    "            continue\n",
    "        \n",
    "        total_keypoints += 1\n",
    "        \n",
    "        # Calculate Euclidean distance between predicted and ground truth keypoints\n",
    "        dist = euclidean((pred_x, pred_y), (gt_x, gt_y))\n",
    "        \n",
    "        # If distance is less than threshold, consider it correct\n",
    "        if dist < threshold_distance:\n",
    "            correct_keypoints += 1\n",
    "    \n",
    "    return (correct_keypoints / total_keypoints) * 100 if total_keypoints > 0 else 0\n",
    "\n",
    "# Calculate Mean Average Precision (mAP)\n",
    "def calculate_map(predictions, ground_truths, image_width, image_height, thresholds=[ 0.2, 0.3, 0.6]):\n",
    "    average_precisions = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        pck_values = []\n",
    "        \n",
    "        print(f\"\\nThreshold: {threshold}\")\n",
    "        \n",
    "        for pred, gt in zip(predictions, ground_truths):\n",
    "            pred_keypoints = pred['keypoints']\n",
    "            gt_keypoints = gt['keypoints']\n",
    "            \n",
    "            pck = calculate_pck(pred_keypoints, gt_keypoints, image_width, image_height, threshold)\n",
    "            pck_values.append(pck)\n",
    "            \n",
    "            # Print the PCK for this image at the current threshold\n",
    "        \n",
    "        # Calculate Average PCK for this threshold\n",
    "        avg_pck = np.mean(pck_values)\n",
    "        average_precisions.append(avg_pck)\n",
    "        \n",
    "        # Print average PCK at this threshold\n",
    "        print(f\"Average PCK @ {threshold}: {avg_pck:.2f}%\")\n",
    "    \n",
    "    return np.mean(average_precisions) if len(average_precisions) > 0 else 0\n",
    "\n",
    "# Process a subset of the dataset (2% of the data)\n",
    "subset_size = int(len(mpii_annotations) * 0.5)  # 2% of the dataset\n",
    "annotations_subset = mpii_annotations[:subset_size]\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "\n",
    "# Process images\n",
    "for idx, annotation in enumerate(annotations_subset):  # Iterate over the 2% subset\n",
    "    img_path = annotation['img_paths']\n",
    "    \n",
    "    \n",
    "    # Get image dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # Process image using MediaPipe Pose model\n",
    "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    if not results.pose_landmarks:\n",
    "        continue\n",
    "    \n",
    "    # Prepare predicted keypoints (only use the first 14 keypoints from 33 keypoints)\n",
    "    predicted_keypoints = [(lm.x * image_width, lm.y * image_height) for i, lm in enumerate(results.pose_landmarks.landmark) if i < 14]  # Only 14 keypoints\n",
    "    \n",
    "    # Prepare ground truth keypoints from the CSV\n",
    "    gt_row = ground_truth_df[ground_truth_df['NAME'] == img_path]\n",
    "    \n",
    "    if not gt_row.empty:\n",
    "        # Extract keypoints from ground truth row\n",
    "        ground_truth_keypoints = [\n",
    "            (gt_row[f'r ankle_X'].values[0], gt_row[f'r ankle_Y'].values[0]),\n",
    "            (gt_row[f'r knee_X'].values[0], gt_row[f'r knee_Y'].values[0]),\n",
    "            (gt_row[f'r hip_X'].values[0], gt_row[f'r hip_Y'].values[0]),\n",
    "            (gt_row[f'l hip_X'].values[0], gt_row[f'l hip_Y'].values[0]),\n",
    "            (gt_row[f'l knee_X'].values[0], gt_row[f'l knee_Y'].values[0]),\n",
    "            (gt_row[f'l ankle_X'].values[0], gt_row[f'l ankle_Y'].values[0]),\n",
    "            (gt_row[f'r wrist_X'].values[0], gt_row[f'r wrist_Y'].values[0]),\n",
    "            (gt_row[f'r elbow_X'].values[0], gt_row[f'r elbow_Y'].values[0]),\n",
    "            (gt_row[f'r shoulder_X'].values[0], gt_row[f'r shoulder_Y'].values[0]),\n",
    "            (gt_row[f'l shoulder_X'].values[0], gt_row[f'l shoulder_Y'].values[0]),\n",
    "            (gt_row[f'l elbow_X'].values[0], gt_row[f'l elbow_Y'].values[0]),\n",
    "            (gt_row[f'l wrist_X'].values[0], gt_row[f'l wrist_Y'].values[0]),\n",
    "            (gt_row[f'head top_X'].values[0], gt_row[f'head top_Y'].values[0])  # Use 'head top' keypoints\n",
    "        ]\n",
    "    \n",
    "        # Optionally include nose if necessary\n",
    "        if 'upper neck_X' in ground_truth_df.columns and 'upper neck_Y' in ground_truth_df.columns:\n",
    "            ground_truth_keypoints.append((gt_row[f'upper neck_X'].values[0], gt_row[f'upper neck_Y'].values[0]))\n",
    "        \n",
    "                \n",
    "        # Ensure that the predicted and ground truth keypoints are consistent\n",
    "        if len(predicted_keypoints) == len(ground_truth_keypoints):\n",
    "            predictions.append({'img_path': img_path, 'keypoints': predicted_keypoints})\n",
    "            ground_truths.append({'img_path': img_path, 'keypoints': ground_truth_keypoints})\n",
    "        else:\n",
    "            print(f\"Skipping {img_path} due to mismatch in keypoints count.\")\n",
    "    \n",
    "# After processing the subset, calculate mAP\n",
    "print(\"Calculating Mean Average Precision (mAP)...\")\n",
    "mean_ap = calculate_map(predictions, ground_truths, image_width, image_height)\n",
    "print(f'Mean Average Precision (mAP): {mean_ap:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T06:17:01.723740Z",
     "iopub.status.busy": "2025-01-05T06:17:01.723401Z",
     "iopub.status.idle": "2025-01-05T06:17:01.729756Z",
     "shell.execute_reply": "2025-01-05T06:17:01.729062Z",
     "shell.execute_reply.started": "2025-01-05T06:17:01.723713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'NAME', 'r ankle_X', 'r ankle_Y', 'r knee_X', 'r knee_Y',\n",
      "       'r hip_X', 'r hip_Y', 'l hip_X', 'l hip_Y', 'l knee_X', 'l knee_Y',\n",
      "       'l ankle_X', 'l ankle_Y', 'pelvis_X', 'pelvis_Y', 'thorax_X',\n",
      "       'thorax_Y', 'upper neck_X', 'upper neck_Y', 'head top_X', 'head top_Y',\n",
      "       'r wrist_X', 'r wrist_Y', 'r elbow_X', 'r elbow_Y', 'r shoulder_X',\n",
      "       'r shoulder_Y', 'l shoulder_X', 'l shoulder_Y', 'l elbow_X',\n",
      "       'l elbow_Y', 'l wrist_X', 'l wrist_Y', 'Scale', 'Activity', 'Category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T15:35:22.538986Z",
     "iopub.status.busy": "2025-01-05T15:35:22.538637Z",
     "iopub.status.idle": "2025-01-05T15:54:31.946106Z",
     "shell.execute_reply": "2025-01-05T15:54:31.945410Z",
     "shell.execute_reply.started": "2025-01-05T15:35:22.538958Z"
    },
    "id": "F8tS0ZTLN-Jh",
    "outputId": "19f0e803-1a32-4f0e-ee97-852eb36e33ee",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Evaluating image 100 of 8686...\n",
      "Evaluating image 200 of 8686...\n",
      "Evaluating image 300 of 8686...\n",
      "Evaluating image 400 of 8686...\n",
      "Evaluating image 500 of 8686...\n",
      "Evaluating image 600 of 8686...\n",
      "Evaluating image 700 of 8686...\n",
      "Evaluating image 800 of 8686...\n",
      "Evaluating image 900 of 8686...\n",
      "Evaluating image 1000 of 8686...\n",
      "Evaluating image 1100 of 8686...\n",
      "Evaluating image 1200 of 8686...\n",
      "Evaluating image 1300 of 8686...\n",
      "Evaluating image 1400 of 8686...\n",
      "Evaluating image 1500 of 8686...\n",
      "Evaluating image 1600 of 8686...\n",
      "Evaluating image 1700 of 8686...\n",
      "Evaluating image 1800 of 8686...\n",
      "Evaluating image 1900 of 8686...\n",
      "Evaluating image 2000 of 8686...\n",
      "Evaluating image 2100 of 8686...\n",
      "Evaluating image 2200 of 8686...\n",
      "Evaluating image 2300 of 8686...\n",
      "Evaluating image 2400 of 8686...\n",
      "Evaluating image 2500 of 8686...\n",
      "Evaluating image 2600 of 8686...\n",
      "Evaluating image 2700 of 8686...\n",
      "Evaluating image 2800 of 8686...\n",
      "Evaluating image 2900 of 8686...\n",
      "Evaluating image 3000 of 8686...\n",
      "Evaluating image 3100 of 8686...\n",
      "Evaluating image 3200 of 8686...\n",
      "Evaluating image 3300 of 8686...\n",
      "Evaluating image 3400 of 8686...\n",
      "Evaluating image 3500 of 8686...\n",
      "Evaluating image 3600 of 8686...\n",
      "Evaluating image 3700 of 8686...\n",
      "Evaluating image 3800 of 8686...\n",
      "Evaluating image 3900 of 8686...\n",
      "Evaluating image 4000 of 8686...\n",
      "Evaluating image 4100 of 8686...\n",
      "Evaluating image 4200 of 8686...\n",
      "Evaluating image 4300 of 8686...\n",
      "Evaluating image 4400 of 8686...\n",
      "Evaluating image 4500 of 8686...\n",
      "Evaluating image 4600 of 8686...\n",
      "Evaluating image 4700 of 8686...\n",
      "Evaluating image 4800 of 8686...\n",
      "Evaluating image 4900 of 8686...\n",
      "Evaluating image 5000 of 8686...\n",
      "Evaluating image 5100 of 8686...\n",
      "Evaluating image 5200 of 8686...\n",
      "Evaluating image 5300 of 8686...\n",
      "Evaluating image 5400 of 8686...\n",
      "Evaluating image 5500 of 8686...\n",
      "Evaluating image 5600 of 8686...\n",
      "Evaluating image 5700 of 8686...\n",
      "Evaluating image 5800 of 8686...\n",
      "Evaluating image 5900 of 8686...\n",
      "Evaluating image 6000 of 8686...\n",
      "Evaluating image 6100 of 8686...\n",
      "Evaluating image 6200 of 8686...\n",
      "Evaluating image 6300 of 8686...\n",
      "Evaluating image 6400 of 8686...\n",
      "Evaluating image 6500 of 8686...\n",
      "Evaluating image 6600 of 8686...\n",
      "Evaluating image 6700 of 8686...\n",
      "Evaluating image 6800 of 8686...\n",
      "Evaluating image 6900 of 8686...\n",
      "Evaluating image 7000 of 8686...\n",
      "Evaluating image 7100 of 8686...\n",
      "Evaluating image 7200 of 8686...\n",
      "Evaluating image 7300 of 8686...\n",
      "Evaluating image 7400 of 8686...\n",
      "Evaluating image 7500 of 8686...\n",
      "Evaluating image 7600 of 8686...\n",
      "Evaluating image 7700 of 8686...\n",
      "Evaluating image 7800 of 8686...\n",
      "Evaluating image 7900 of 8686...\n",
      "Evaluating image 8000 of 8686...\n",
      "Evaluating image 8100 of 8686...\n",
      "Evaluating image 8200 of 8686...\n",
      "Evaluating image 8300 of 8686...\n",
      "Evaluating image 8400 of 8686...\n",
      "Evaluating image 8500 of 8686...\n",
      "Evaluating image 8600 of 8686...\n",
      "Evaluating image 100 of 8686...\n",
      "Evaluating image 200 of 8686...\n",
      "Evaluating image 300 of 8686...\n",
      "Evaluating image 400 of 8686...\n",
      "Evaluating image 500 of 8686...\n",
      "Evaluating image 600 of 8686...\n",
      "Evaluating image 700 of 8686...\n",
      "Evaluating image 800 of 8686...\n",
      "Evaluating image 900 of 8686...\n",
      "Evaluating image 1000 of 8686...\n",
      "Evaluating image 1100 of 8686...\n",
      "Evaluating image 1200 of 8686...\n",
      "Evaluating image 1300 of 8686...\n",
      "Evaluating image 1400 of 8686...\n",
      "Evaluating image 1500 of 8686...\n",
      "Evaluating image 1600 of 8686...\n",
      "Evaluating image 1700 of 8686...\n",
      "Evaluating image 1800 of 8686...\n",
      "Evaluating image 1900 of 8686...\n",
      "Evaluating image 2000 of 8686...\n",
      "Evaluating image 2100 of 8686...\n",
      "Evaluating image 2200 of 8686...\n",
      "Evaluating image 2300 of 8686...\n",
      "Evaluating image 2400 of 8686...\n",
      "Evaluating image 2500 of 8686...\n",
      "Evaluating image 2600 of 8686...\n",
      "Evaluating image 2700 of 8686...\n",
      "Evaluating image 2800 of 8686...\n",
      "Evaluating image 2900 of 8686...\n",
      "Evaluating image 3000 of 8686...\n",
      "Evaluating image 3100 of 8686...\n",
      "Evaluating image 3200 of 8686...\n",
      "Evaluating image 3300 of 8686...\n",
      "Evaluating image 3400 of 8686...\n",
      "Evaluating image 3500 of 8686...\n",
      "Evaluating image 3600 of 8686...\n",
      "Evaluating image 3700 of 8686...\n",
      "Evaluating image 3800 of 8686...\n",
      "Evaluating image 3900 of 8686...\n",
      "Evaluating image 4000 of 8686...\n",
      "Evaluating image 4100 of 8686...\n",
      "Evaluating image 4200 of 8686...\n",
      "Evaluating image 4300 of 8686...\n",
      "Evaluating image 4400 of 8686...\n",
      "Evaluating image 4500 of 8686...\n",
      "Evaluating image 4600 of 8686...\n",
      "Evaluating image 4700 of 8686...\n",
      "Evaluating image 4800 of 8686...\n",
      "Evaluating image 4900 of 8686...\n",
      "Evaluating image 5000 of 8686...\n",
      "Evaluating image 5100 of 8686...\n",
      "Evaluating image 5200 of 8686...\n",
      "Evaluating image 5300 of 8686...\n",
      "Evaluating image 5400 of 8686...\n",
      "Evaluating image 5500 of 8686...\n",
      "Evaluating image 5600 of 8686...\n",
      "Evaluating image 5700 of 8686...\n",
      "Evaluating image 5800 of 8686...\n",
      "Evaluating image 5900 of 8686...\n",
      "Evaluating image 6000 of 8686...\n",
      "Evaluating image 6100 of 8686...\n",
      "Evaluating image 6200 of 8686...\n",
      "Evaluating image 6300 of 8686...\n",
      "Evaluating image 6400 of 8686...\n",
      "Evaluating image 6500 of 8686...\n",
      "Evaluating image 6600 of 8686...\n",
      "Evaluating image 6700 of 8686...\n",
      "Evaluating image 6800 of 8686...\n",
      "Evaluating image 6900 of 8686...\n",
      "Evaluating image 7000 of 8686...\n",
      "Evaluating image 7100 of 8686...\n",
      "Evaluating image 7200 of 8686...\n",
      "Evaluating image 7300 of 8686...\n",
      "Evaluating image 7400 of 8686...\n",
      "Evaluating image 7500 of 8686...\n",
      "Evaluating image 7600 of 8686...\n",
      "Evaluating image 7700 of 8686...\n",
      "Evaluating image 7800 of 8686...\n",
      "Evaluating image 7900 of 8686...\n",
      "Evaluating image 8000 of 8686...\n",
      "Evaluating image 8100 of 8686...\n",
      "Evaluating image 8200 of 8686...\n",
      "Evaluating image 8300 of 8686...\n",
      "Evaluating image 8400 of 8686...\n",
      "Evaluating image 8500 of 8686...\n",
      "Evaluating image 8600 of 8686...\n",
      "Evaluating image 100 of 8686...\n",
      "Evaluating image 200 of 8686...\n",
      "Evaluating image 300 of 8686...\n",
      "Evaluating image 400 of 8686...\n",
      "Evaluating image 500 of 8686...\n",
      "Evaluating image 600 of 8686...\n",
      "Evaluating image 700 of 8686...\n",
      "Evaluating image 800 of 8686...\n",
      "Evaluating image 900 of 8686...\n",
      "Evaluating image 1000 of 8686...\n",
      "Evaluating image 1100 of 8686...\n",
      "Evaluating image 1200 of 8686...\n",
      "Evaluating image 1300 of 8686...\n",
      "Evaluating image 1400 of 8686...\n",
      "Evaluating image 1500 of 8686...\n",
      "Evaluating image 1600 of 8686...\n",
      "Evaluating image 1700 of 8686...\n",
      "Evaluating image 1800 of 8686...\n",
      "Evaluating image 1900 of 8686...\n",
      "Evaluating image 2000 of 8686...\n",
      "Evaluating image 2100 of 8686...\n",
      "Evaluating image 2200 of 8686...\n",
      "Evaluating image 2300 of 8686...\n",
      "Evaluating image 2400 of 8686...\n",
      "Evaluating image 2500 of 8686...\n",
      "Evaluating image 2600 of 8686...\n",
      "Evaluating image 2700 of 8686...\n",
      "Evaluating image 2800 of 8686...\n",
      "Evaluating image 2900 of 8686...\n",
      "Evaluating image 3000 of 8686...\n",
      "Evaluating image 3100 of 8686...\n",
      "Evaluating image 3200 of 8686...\n",
      "Evaluating image 3300 of 8686...\n",
      "Evaluating image 3400 of 8686...\n",
      "Evaluating image 3500 of 8686...\n",
      "Evaluating image 3600 of 8686...\n",
      "Evaluating image 3700 of 8686...\n",
      "Evaluating image 3800 of 8686...\n",
      "Evaluating image 3900 of 8686...\n",
      "Evaluating image 4000 of 8686...\n",
      "Evaluating image 4100 of 8686...\n",
      "Evaluating image 4200 of 8686...\n",
      "Evaluating image 4300 of 8686...\n",
      "Evaluating image 4400 of 8686...\n",
      "Evaluating image 4500 of 8686...\n",
      "Evaluating image 4600 of 8686...\n",
      "Evaluating image 4700 of 8686...\n",
      "Evaluating image 4800 of 8686...\n",
      "Evaluating image 4900 of 8686...\n",
      "Evaluating image 5000 of 8686...\n",
      "Evaluating image 5100 of 8686...\n",
      "Evaluating image 5200 of 8686...\n",
      "Evaluating image 5300 of 8686...\n",
      "Evaluating image 5400 of 8686...\n",
      "Evaluating image 5500 of 8686...\n",
      "Evaluating image 5600 of 8686...\n",
      "Evaluating image 5700 of 8686...\n",
      "Evaluating image 5800 of 8686...\n",
      "Evaluating image 5900 of 8686...\n",
      "Evaluating image 6000 of 8686...\n",
      "Evaluating image 6100 of 8686...\n",
      "Evaluating image 6200 of 8686...\n",
      "Evaluating image 6300 of 8686...\n",
      "Evaluating image 6400 of 8686...\n",
      "Evaluating image 6500 of 8686...\n",
      "Evaluating image 6600 of 8686...\n",
      "Evaluating image 6700 of 8686...\n",
      "Evaluating image 6800 of 8686...\n",
      "Evaluating image 6900 of 8686...\n",
      "Evaluating image 7000 of 8686...\n",
      "Evaluating image 7100 of 8686...\n",
      "Evaluating image 7200 of 8686...\n",
      "Evaluating image 7300 of 8686...\n",
      "Evaluating image 7400 of 8686...\n",
      "Evaluating image 7500 of 8686...\n",
      "Evaluating image 7600 of 8686...\n",
      "Evaluating image 7700 of 8686...\n",
      "Evaluating image 7800 of 8686...\n",
      "Evaluating image 7900 of 8686...\n",
      "Evaluating image 8000 of 8686...\n",
      "Evaluating image 8100 of 8686...\n",
      "Evaluating image 8200 of 8686...\n",
      "Evaluating image 8300 of 8686...\n",
      "Evaluating image 8400 of 8686...\n",
      "Evaluating image 8500 of 8686...\n",
      "Evaluating image 8600 of 8686...\n",
      "PCK at threshold 0.2: 13.45\n",
      "Precision at threshold 0.2: 0.20\n",
      "Recall at threshold 0.2: 0.32\n",
      "PCK at threshold 0.3: 22.17\n",
      "Precision at threshold 0.3: 0.33\n",
      "Recall at threshold 0.3: 0.40\n",
      "PCK at threshold 0.6: 41.68\n",
      "Precision at threshold 0.6: 0.63\n",
      "Recall at threshold 0.6: 0.52\n",
      "Mean Average Precision (mAP): 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24515486698597452"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "import random\n",
    "\n",
    "# Load CSV and JSON data\n",
    "csv_keypoints_path = '/kaggle/input/mpii-human-pose/mpii_human_pose.csv'\n",
    "ground_truth_df = pd.read_csv(csv_keypoints_path)\n",
    "\n",
    "# Example of body parts we are considering\n",
    "BODY_PARTS = {\n",
    "    \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "    \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "    \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "    \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18\n",
    "}\n",
    "\n",
    "# Matching the 14 keypoints of interest from the CSV columns:\n",
    "KEYPOINTS = [\n",
    "    'r ankle_X', 'r ankle_Y', 'r knee_X', 'r knee_Y', 'r hip_X', 'r hip_Y',\n",
    "    'l hip_X', 'l hip_Y', 'l knee_X', 'l knee_Y', 'l ankle_X', 'l ankle_Y',\n",
    "    'r wrist_X', 'r wrist_Y', 'r elbow_X', 'r elbow_Y', 'r shoulder_X', 'r shoulder_Y',\n",
    "    'l shoulder_X', 'l shoulder_Y', 'l elbow_X', 'l elbow_Y', 'l wrist_X', 'l wrist_Y',\n",
    "    'head top_X', 'head top_Y', 'upper neck_X', 'upper neck_Y'\n",
    "]\n",
    "\n",
    "# Function to calculate PCK\n",
    "def calculate_pck(predicted_keypoints, ground_truth_keypoints, image_width, image_height, threshold=0.05):\n",
    "    threshold_distance = threshold * np.sqrt(image_width**2 + image_height**2)\n",
    "    correct_keypoints = 0\n",
    "    total_keypoints = 0\n",
    "\n",
    "    for pred, gt in zip(predicted_keypoints, ground_truth_keypoints):\n",
    "        if gt is None:  # Skip missing ground truth points\n",
    "            continue\n",
    "        total_keypoints += 1\n",
    "        if pred is not None and euclidean(pred, gt) < threshold_distance:\n",
    "            correct_keypoints += 1\n",
    "\n",
    "    return (correct_keypoints / total_keypoints) * 100 if total_keypoints > 0 else 0\n",
    "\n",
    "# Function to calculate Precision and Recall for each keypoint\n",
    "def calculate_precision_recall(predicted_keypoints, ground_truth_keypoints, image_width, image_height, threshold=0.2):\n",
    "    threshold_distance = threshold * np.sqrt(image_width**2 + image_height**2)\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    \n",
    "    for pred, gt in zip(predicted_keypoints, ground_truth_keypoints):\n",
    "        if gt is None:  # Skip missing ground truth points\n",
    "            continue\n",
    "        \n",
    "        if pred is not None and euclidean(pred, gt) < threshold_distance:\n",
    "            tp += 1  # True positive: correctly detected\n",
    "        elif pred is not None:\n",
    "            fp += 1  # False positive: detected but incorrect\n",
    "        else:\n",
    "            fn += 1  # False negative: not detected\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# Function to process predictions and ground truths\n",
    "def process_images_and_calculate_pck(predictions, ground_truths, image_width, image_height, thresholds=[0.2, 0.3, 0.6]):\n",
    "    pck_values = {threshold: [] for threshold in thresholds}\n",
    "    precision_values = {threshold: [] for threshold in thresholds}\n",
    "    recall_values = {threshold: [] for threshold in thresholds}\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        for idx, (pred, gt) in enumerate(zip(predictions, ground_truths)):\n",
    "            if (idx + 1) % 100 == 0:  # Print progress every 10 images\n",
    "                print(f\"Evaluating image {idx + 1} of {len(predictions)}...\")\n",
    "\n",
    "            pred_keypoints = pred['keypoints']\n",
    "            gt_keypoints = gt['keypoints']\n",
    "\n",
    "            # Calculate PCK for this threshold\n",
    "            pck = calculate_pck(pred_keypoints, gt_keypoints, image_width, image_height, threshold)\n",
    "            pck_values[threshold].append(pck)\n",
    "\n",
    "            # Calculate Precision and Recall\n",
    "            precision, recall = calculate_precision_recall(pred_keypoints, gt_keypoints, image_width, image_height, threshold)\n",
    "            precision_values[threshold].append(precision)\n",
    "            recall_values[threshold].append(recall)\n",
    "\n",
    "    # Calculate and print Average Precision (AP) for each threshold\n",
    "    for threshold in thresholds:\n",
    "        avg_pck = np.mean(pck_values[threshold]) if pck_values[threshold] else 0\n",
    "        avg_precision = np.mean(precision_values[threshold]) if precision_values[threshold] else 0\n",
    "        avg_recall = np.mean(recall_values[threshold]) if recall_values[threshold] else 0\n",
    "\n",
    "        print(f\"PCK at threshold {threshold}: {avg_pck:.2f}\")\n",
    "        print(f\"Precision at threshold {threshold}: {avg_precision:.2f}\")\n",
    "        print(f\"Recall at threshold {threshold}: {avg_recall:.2f}\")\n",
    "\n",
    "# Calculate mAP\n",
    "def calculate_map(predictions, ground_truths, thresholds):\n",
    "    ap_values = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        \n",
    "        for pred, gt in zip(predictions, ground_truths):\n",
    "            pred_keypoints = pred['keypoints']\n",
    "            gt_keypoints = gt['keypoints']\n",
    "            \n",
    "            # Get precision and recall for this keypoint at the threshold\n",
    "            precision, recall = calculate_precision_recall(pred_keypoints, gt_keypoints, 368, 368, threshold)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "        \n",
    "        # Average precision for the threshold\n",
    "        ap = np.mean(precision_list) if precision_list else 0\n",
    "        ap_values.append(ap)\n",
    "\n",
    "    mAP = np.mean(ap_values)\n",
    "    print(f\"Mean Average Precision (mAP): {mAP:.2f}\")\n",
    "    return mAP\n",
    "\n",
    "# Path to the TensorFlow model\n",
    "model_path = '/kaggle/input/graph_opt.pb/tensorflow2/default/1/graph_opt.pb'\n",
    "\n",
    "# Load the model\n",
    "net = cv.dnn.readNetFromTensorflow(model_path)\n",
    "\n",
    "# Image directory and CSV keypoints path\n",
    "image_dir = '/kaggle/input/mpii-human-pose/mpii_human_pose_v1/images'\n",
    "csv_keypoints_path = '/kaggle/input/mpii-human-pose/mpii_human_pose.csv'\n",
    "\n",
    "# Reading the images and matching ground truth\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "\n",
    "# Get 2% of the dataset\n",
    "sample_size = int(len(ground_truth_df) * 0.5)\n",
    "sampled_indices = random.sample(range(len(ground_truth_df)), sample_size)\n",
    "\n",
    "# Iterate through the subset of 2% images\n",
    "for idx, row in ground_truth_df.iloc[sampled_indices].iterrows():\n",
    "    img_path = row['NAME']\n",
    "    image = cv.imread(f\"{image_dir}/{img_path}\")\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Image {img_path} could not be loaded, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Get image dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Process the image with the model\n",
    "    net.setInput(cv.dnn.blobFromImage(image, 1.0, (368, 368), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]  # We need the first 19 elements for pose estimation\n",
    "\n",
    "    points = []\n",
    "    for i in range(14):  # Extract first 14 keypoints\n",
    "        heat_map = out[0, i, :, :]\n",
    "        _, conf, _, point = cv.minMaxLoc(heat_map)\n",
    "        x = (image_width * point[0]) / out.shape[3]\n",
    "        y = (image_height * point[1]) / out.shape[2]\n",
    "        points.append((int(x), int(y)) if conf > 0.2 else None)\n",
    "\n",
    "    # Prepare predicted keypoints\n",
    "    predictions.append({'img_path': img_path, 'keypoints': points})\n",
    "\n",
    "    # Prepare ground truth keypoints (from CSV)\n",
    "    ground_truth_keypoints = []\n",
    "    for keypoint in KEYPOINTS:\n",
    "        if pd.isna(row[keypoint]):\n",
    "            ground_truth_keypoints.append(None)\n",
    "        else:\n",
    "            ground_truth_keypoints.append((row[keypoint], row[keypoint.replace('X', 'Y')]))\n",
    "\n",
    "    ground_truths.append({'img_path': img_path, 'keypoints': ground_truth_keypoints})\n",
    "\n",
    "# Now calculate the PCK and mAP for different thresholds\n",
    "print(\"Starting evaluation...\")\n",
    "process_images_and_calculate_pck(predictions, ground_truths, image_width, image_height, thresholds=[0.2, 0.3, 0.6])\n",
    "\n",
    "# Calculate mAP\n",
    "calculate_map(predictions, ground_truths, thresholds=[ 0.2, 0.3, 0.6])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1722818,
     "sourceId": 3094861,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 206707,
     "modelInstanceId": 184550,
     "sourceId": 216465,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
