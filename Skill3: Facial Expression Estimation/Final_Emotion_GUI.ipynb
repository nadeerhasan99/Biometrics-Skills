{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99406830-b4e7-4168-8a56-c2b607409be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadee\\anaconda3\\envs\\session2\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QPushButton, QFileDialog, QComboBox, \\\n",
    "    QHBoxLayout, QGridLayout\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import Qt, QTimer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load models here\n",
    "model1 = load_model('Final_Facial_Expression_Detection_CNN.h5')  \n",
    "model2 = load_model('Age_Model_res.h5')  \n",
    "\n",
    "# Emotion labels\n",
    "emotion_labels = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Happy', 'Sadness', 'Surprise']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "class EmotionEstimatorApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Face Expression Estimation\")\n",
    "        self.setGeometry(100, 100, 800, 600)  # Default window size\n",
    "\n",
    "        # Layout setup\n",
    "        self.layout = QGridLayout()\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "        # Dropdown to select the model\n",
    "        self.model_dropdown = QComboBox()\n",
    "        self.model_dropdown.addItem(\"CNN\")\n",
    "        self.model_dropdown.addItem(\"RES\")\n",
    "        self.layout.addWidget(self.model_dropdown, 0, 2)\n",
    "\n",
    "        # Label for displaying selected model\n",
    "        self.selected_model_label = QLabel(\"Model: CNN\")\n",
    "        self.layout.addWidget(self.selected_model_label, 0, 0)\n",
    "\n",
    "        # Image Display\n",
    "        self.image_label = QLabel(\"Image/Webcam\")\n",
    "        self.image_label.setAlignment(Qt.AlignCenter)\n",
    "        self.layout.addWidget(self.image_label, 1, 0, 1, 3)\n",
    "\n",
    "        # Buttons for actions\n",
    "        self.upload_button = QPushButton(\"Upload Image\")\n",
    "        self.upload_button.clicked.connect(self.upload_image)\n",
    "        self.layout.addWidget(self.upload_button, 8, 1)\n",
    "\n",
    "        self.webcam_button = QPushButton(\"Open Webcam\")\n",
    "        self.webcam_button.clicked.connect(self.start_webcam)\n",
    "        self.layout.addWidget(self.webcam_button, 6, 1)\n",
    "\n",
    "        self.stop_webcam_button = QPushButton(\"Stop Webcam\")\n",
    "        self.stop_webcam_button.clicked.connect(self.stop_webcam)\n",
    "        self.stop_webcam_button.setEnabled(False)  \n",
    "        self.layout.addWidget(self.stop_webcam_button, 4, 1)\n",
    "\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_webcam)\n",
    "\n",
    "        self.capture = None\n",
    "\n",
    "        self.model_dropdown.currentIndexChanged.connect(self.update_model)\n",
    "\n",
    "    def update_model(self):\n",
    "        \"\"\"Handle model switching based on dropdown selection.\"\"\"\n",
    "        selected_model = self.model_dropdown.currentIndex()\n",
    "        if selected_model == 0:\n",
    "            self.selected_model_label.setText(\"Model: CNN\")\n",
    "        else:\n",
    "            self.selected_model_label.setText(\"Model: RES\")\n",
    "\n",
    "    def upload_image(self):\n",
    "        try:\n",
    "            file_dialog = QFileDialog()\n",
    "            image_path, _ = file_dialog.getOpenFileName()\n",
    "\n",
    "            if image_path:\n",
    "                self.process_image(image_path)\n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error uploading image: {e}\")\n",
    "\n",
    "    def start_webcam(self):\n",
    "        try:\n",
    "            self.capture = cv2.VideoCapture(0)\n",
    "            if not self.capture.isOpened():\n",
    "                self.image_label.setText(\"Failed to open webcam!\")\n",
    "                return\n",
    "            self.webcam_button.setDisabled(True)  \n",
    "            self.stop_webcam_button.setEnabled(True)\n",
    "            self.timer.start(30)  \n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error starting webcam: {e}\")\n",
    "\n",
    "    def stop_webcam(self):\n",
    "        \"\"\"Stop the webcam and release resources.\"\"\"\n",
    "        try:\n",
    "            if self.capture is not None:\n",
    "                self.capture.release()\n",
    "                self.capture = None\n",
    "                self.timer.stop()  \n",
    "                self.webcam_button.setEnabled(True)  \n",
    "                self.stop_webcam_button.setEnabled(False)  \n",
    "                self.image_label.setText(\"Image\\Webcam\")\n",
    "            else:\n",
    "                self.image_label.setText(\"No webcam feed to stop.\")\n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error stopping webcam: {e}\")\n",
    "\n",
    "    def update_webcam(self):\n",
    "        try:\n",
    "            ret, frame = self.capture.read()\n",
    "            if ret:\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                faces = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face = frame_rgb[y:y + h, x:x + w]\n",
    "\n",
    "                    predicted_emotion = self.predict_expression(face)\n",
    "\n",
    "                    cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                    cv2.putText(frame_rgb, predicted_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0),\n",
    "                                2)\n",
    "\n",
    "                self.display_image(frame_rgb)\n",
    "\n",
    "            else:\n",
    "                self.capture.release()\n",
    "                self.capture = None\n",
    "                self.webcam_button.setEnabled(True)\n",
    "                self.stop_webcam_button.setEnabled(False)\n",
    "                self.timer.stop()\n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error during webcam capture: {e}\")\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                face = image_rgb[y:y + h, x:x + w]\n",
    "\n",
    "                predicted_emotion = self.predict_expression(face)\n",
    "\n",
    "                cv2.rectangle(image_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(image_rgb, predicted_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            self.display_image(image_rgb)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error processing image: {e}\")\n",
    "\n",
    "    def display_image(self, image):\n",
    "        try:\n",
    "            height, width, channel = image.shape\n",
    "            bytes_per_line = 3 * width\n",
    "            q_image = QImage(image.data, width, height, bytes_per_line, QImage.Format_RGB888)\n",
    "            pixmap = QPixmap(q_image)\n",
    "            self.image_label.setPixmap(\n",
    "                pixmap.scaled(self.image_label.width(), self.image_label.height(), Qt.KeepAspectRatio))\n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error displaying image: {e}\")\n",
    "\n",
    "    def predict_expression(self, image):\n",
    "        try:\n",
    "            \n",
    "            image_resized = cv2.resize(image, (48, 48))  \n",
    "            image_array = img_to_array(image_resized)  \n",
    "            image_array = np.expand_dims(image_array, axis=0)  \n",
    "            image_array = image_array / 255.0 \n",
    "\n",
    "            selected_model = self.model_dropdown.currentIndex()\n",
    "            if selected_model == 0:\n",
    "                model = model1\n",
    "            else:\n",
    "                model = model2\n",
    "\n",
    "            # Make prediction\n",
    "            prediction = model.predict(image_array)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "            return emotion_labels[predicted_class]\n",
    "        except Exception as e:\n",
    "            self.image_label.setText(f\"Error predicting emotion: {e}\")\n",
    "            return \"Error\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    window = EmotionEstimatorApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6a6ed-e955-4889-9b54-2de571fce473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
